from transformers import BertTokenizer, BertModel
import torch

# KoBERT ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (monologg/kobert from HuggingFace)
tokenizer = BertTokenizer.from_pretrained("monologg/kobert")
# model = BertModel.from_pretrained("monologg/kobert")
# model.eval()

# ê°„ë‹¨í•œ ê·œì¹™ ê¸°ë°˜ ì‘ë‹µ (ì„ì‹œ)
def get_kobert_response(user_input):
    inputs = tokenizer(user_input, return_tensors="pt")
    # with torch.no_grad():
    #     _ = model(**inputs)

    # ì„ì‹œ ê·œì¹™ ì‘ë‹µ
    if "ì´ë¦„" in user_input:
        return "ì €ëŠ” CoBa ì±—ë´‡ì…ë‹ˆë‹¤!"
    elif "ì·¨ë¯¸" in user_input:
        return "ì»¤í”¼ ë‚´ë¦¬ê¸°ì™€ ë°ì´í„° ë¶„ì„ì´ìš” â˜•ğŸ“Š"
    elif "ê²½ë ¥" in user_input:
        return "ë°ì´í„° ë¶„ì„ê³¼ AI ê¸°íš ê²½ë ¥ì´ ìˆì–´ìš”."
    elif "ìê²©ì¦" in user_input:
        return "ì •ë³´ì²˜ë¦¬ê¸°ì‚¬, ë¹…ë°ì´í„°ë¶„ì„ê¸°ì‚¬ ë“± ë³´ìœ  ì¤‘ì…ë‹ˆë‹¤."
    else:
        return "ë” ê¶ê¸ˆí•œ ê±¸ ë¬¼ì–´ë´ ì£¼ì„¸ìš”!"